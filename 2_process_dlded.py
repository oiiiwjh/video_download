import pandas as pd
import os
# 从指定csv文件中，按照id将其中条目分开，分别保存到不同的csv文件中
# ---------------------------------------------------------
# select the longest video from a csv file
def seletect_longest_video():
    
    # 按照hours列的值降序排序
    df_src = df_src.sort_values(by='hours', ascending=False)
    print(len(df_src))

    # 初始化新的数据列表
    pd_new_list = []
    video_url = []
    i = 0
    pd_i = -1

    # 遍历df_src，选择前10000个不在ids中的视频
    while i < 10000:
        pd_i += 1
        id_src = os.path.basename(df_src.iloc[pd_i]['video_url']).split('=')[-1]
        if id_src in ids:
            continue
        pd_new_list.append(df_src.iloc[pd_i])
        video_url.append(df_src.iloc[pd_i]['video_url'])
        i += 1
        if i % 10 == 0:
            print(len(video_url), i, pd_i, df_src.iloc[pd_i]['video_url'], df_src.iloc[pd_i]['hours'])

    print(len(video_url))

    # 将选择的视频路径保存到bigger_videos.txt文件中
    with open('bigger_videos.txt', 'w') as f:
        for path in video_url:
            f.write(f"{path}\n")
    # seletect longest video rows from df_src, and save it to bigger_videos.txt/csv
    df_src = df_src[df_src['video_url'].isin(video_url)]
    df_src.to_csv('bigger_videos.csv', index=False)
    
    # pass

if __name__ == '__main__':
    date = '0420'
    vid_dir = f'/share/wjh/{date}'
    # vid_dir = '/share/wjh/raw_videos/total_done_sample_baidu'
    # meta_data csv generated by 1_process_folder2csv.py
    done_csv = f'/share/wjh/meta_data_{date}.csv'
    # done_csv = '/home/wjh/projects/vid_download/total_done_sample_baidu.csv'
    # raw csv file
    src_csv = '/home/wjh/projects/vid_download/meta_infos/meta_info_0410.csv'
    
    # 2 csv file to be generated(done and non-done)
    done_tgt_csv = f'/home/wjh/projects/vid_download/meta_infos/meta_info_{date}_done.csv'
    non_done_tgt_csv = f'/home/wjh/projects/vid_download/meta_infos/meta_info_{date}.csv'
    # load done and src csv
    done_pd = pd.read_csv(done_csv)    
    src_csv_pd = pd.read_csv(src_csv)
    ids = list(done_pd['id'])
    print(len(ids))
    # 若src_csv_pd中，没有id这一列, 则需要添加
    if 'id' not in src_csv_pd.columns:
        src_csv_pd['id'] = src_csv_pd['video_url'].apply(lambda x: os.path.basename(x).split('=')[-1])
        print(src_csv_pd['id'][0])
    done_tgt_df = src_csv_pd[src_csv_pd['id'].isin(ids)]
    non_done_tgt_df = src_csv_pd[~src_csv_pd['id'].isin(ids)]
    # update video_path for done_tgt_df
    done_tgt_df['video_path'] = done_tgt_df['id'].apply(lambda x: os.path.join(vid_dir,  x+'.mp4') if os.path.exists(os.path.join(vid_dir, x+'.mp4')) else os.path.join(vid_dir, x+'.webm'))
    # save to csv
    print(f'done: {len(done_tgt_df)}, non-done: {len(non_done_tgt_df)}')
    done_tgt_df.to_csv(done_tgt_csv, index=False)
    non_done_tgt_df.to_csv(non_done_tgt_csv, index=False)